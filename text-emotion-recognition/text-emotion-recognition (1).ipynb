{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8525261,"sourceType":"datasetVersion","datasetId":5090832},{"sourceId":8529975,"sourceType":"datasetVersion","datasetId":5094277}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nimport re\nfrom nltk.corpus import wordnet\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom imblearn.over_sampling import SMOTE\nfrom nltk.corpus import stopwords\nimport nltk\n\nfile_path = '/kaggle/input/mergeddataset/merged_dataset_fix_updated.csv'\ndataset = pd.read_csv(file_path)\n\ndataset.dropna(inplace=True)\n\ndef clean_text(text):\n    text = re.sub(r'\\[USERNAME\\]', '', text)  \n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  \n    text = text.lower()  \n    text = text.strip()  \n    return text\n\ndataset['cleaned_text'] = dataset['text'].apply(clean_text)\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:28:45.422668Z","iopub.execute_input":"2024-05-27T13:28:45.423027Z","iopub.status.idle":"2024-05-27T13:28:45.748065Z","shell.execute_reply.started":"2024-05-27T13:28:45.422999Z","shell.execute_reply":"2024-05-27T13:28:45.746938Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text label  \\\n0  Saya merasa bahwa itu menciptakan lingkungan y...  fear   \n1                  Saya merasa enggan meminta apapun  fear   \n2  Saya takut untuk benar -benar menunjukkan apa ...  fear   \n3  Saya pikir dia merasa sedikit tidak berdaya da...  fear   \n4                         Saya tentu merasa tersiksa  fear   \n\n                                        cleaned_text  \n0  saya merasa bahwa itu menciptakan lingkungan y...  \n1                  saya merasa enggan meminta apapun  \n2  saya takut untuk benar benar menunjukkan apa y...  \n3  saya pikir dia merasa sedikit tidak berdaya da...  \n4                         saya tentu merasa tersiksa  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Saya merasa bahwa itu menciptakan lingkungan y...</td>\n      <td>fear</td>\n      <td>saya merasa bahwa itu menciptakan lingkungan y...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Saya merasa enggan meminta apapun</td>\n      <td>fear</td>\n      <td>saya merasa enggan meminta apapun</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Saya takut untuk benar -benar menunjukkan apa ...</td>\n      <td>fear</td>\n      <td>saya takut untuk benar benar menunjukkan apa y...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Saya pikir dia merasa sedikit tidak berdaya da...</td>\n      <td>fear</td>\n      <td>saya pikir dia merasa sedikit tidak berdaya da...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Saya tentu merasa tersiksa</td>\n      <td>fear</td>\n      <td>saya tentu merasa tersiksa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"nltk.download('stopwords')\n\nprint(\"Distribusi awal label:\")\nprint(dataset['label'].value_counts())\n\nvectorizer = TfidfVectorizer(stop_words=stopwords.words('indonesian'))\nX = vectorizer.fit_transform(dataset['text'])\ny = dataset['label']\n\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\nX_resampled_texts = vectorizer.inverse_transform(X_resampled)\nX_resampled_texts = [' '.join(text) for text in X_resampled_texts]\n\ndf_resampled = pd.DataFrame({'text': X_resampled_texts, 'label': y_resampled})\n\nprint(\"Distribusi label setelah augmentasi:\")\nprint(df_resampled['label'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:28:45.750009Z","iopub.execute_input":"2024-05-27T13:28:45.751096Z","iopub.status.idle":"2024-05-27T13:29:03.491213Z","shell.execute_reply.started":"2024-05-27T13:28:45.751052Z","shell.execute_reply":"2024-05-27T13:29:03.490244Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nDistribusi awal label:\nlabel\nanger       6101\nfear        6049\nlove        6037\nhappy       6017\nsurprise    6000\nsadness     5997\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Distribusi label setelah augmentasi:\nlabel\nfear        6101\nsadness     6101\nlove        6101\nhappy       6101\nsurprise    6101\nanger       6101\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf_resampled['label'] = label_encoder.fit_transform(df_resampled['label'])\n\nX_train, X_test, y_train, y_test = train_test_split(df_resampled['text'], df_resampled['label'], test_size=0.2, random_state=42)\n\nmodel_name = \"indobenchmark/indobert-base-p1\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n\ndef encode_texts(texts, tokenizer, max_len=128):\n    return tokenizer(\n        texts.tolist(),\n        max_length=max_len,\n        truncation=True,\n        padding='max_length',\n        return_tensors='tf'\n    )\n\ntrain_encodings = encode_texts(X_train, tokenizer)\ntest_encodings = encode_texts(X_test, tokenizer)\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(train_encodings),\n    y_train.values\n)).shuffle(len(X_train)).batch(16)\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((\n    dict(test_encodings),\n    y_test.values\n)).batch(16)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:29:03.492773Z","iopub.execute_input":"2024-05-27T13:29:03.493624Z","iopub.status.idle":"2024-05-27T13:29:20.995816Z","shell.execute_reply.started":"2024-05-27T13:29:03.493558Z","shell.execute_reply":"2024-05-27T13:29:20.994673Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n\nmodel.compile(optimizer=optimizer, \n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n              metrics=['accuracy'])\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n\nhistory = model.fit(train_dataset,\n                    epochs=5,\n                    validation_data=test_dataset,\n                    callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:29:20.998452Z","iopub.execute_input":"2024-05-27T13:29:20.998871Z","iopub.status.idle":"2024-05-27T14:13:45.545469Z","shell.execute_reply.started":"2024-05-27T13:29:20.998835Z","shell.execute_reply":"2024-05-27T14:13:45.544447Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1831/1831 [==============================] - 598s 291ms/step - loss: 0.7411 - accuracy: 0.7400 - val_loss: 0.5615 - val_accuracy: 0.8029\nEpoch 2/5\n1831/1831 [==============================] - 517s 282ms/step - loss: 0.4312 - accuracy: 0.8518 - val_loss: 0.4565 - val_accuracy: 0.8480\nEpoch 3/5\n1831/1831 [==============================] - 517s 282ms/step - loss: 0.2717 - accuracy: 0.9104 - val_loss: 0.3960 - val_accuracy: 0.8787\nEpoch 4/5\n1831/1831 [==============================] - 516s 282ms/step - loss: 0.1759 - accuracy: 0.9428 - val_loss: 0.4515 - val_accuracy: 0.8675\nEpoch 5/5\n1831/1831 [==============================] - 516s 282ms/step - loss: 0.1481 - accuracy: 0.9512 - val_loss: 0.4718 - val_accuracy: 0.8836\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, precision_score, recall_score\n\n# Predict on the test dataset\ny_pred_probs = model.predict(test_dataset).logits\ny_pred = tf.argmax(y_pred_probs, axis=1).numpy()\n\n# Confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Classification report\nclass_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\nprint(\"Classification Report:\")\nprint(class_report)\n\n# Evaluation metrics\naccuracy = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred, average='weighted')\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Sensitivity (Recall): {recall:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:28:55.888732Z","iopub.execute_input":"2024-05-27T14:28:55.889139Z","iopub.status.idle":"2024-05-27T14:29:38.511119Z","shell.execute_reply.started":"2024-05-27T14:28:55.889106Z","shell.execute_reply":"2024-05-27T14:29:38.510137Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"458/458 [==============================] - 42s 93ms/step\nConfusion Matrix:\n[[1133   44   18    1   38    5]\n [  28 1096   28    5   12   63]\n [  48   57 1046   69   41   19]\n [  12   13   28 1110   28    3]\n [  66   72   60   24  965   15]\n [   7   31   37    2   14 1084]]\nClassification Report:\n              precision    recall  f1-score   support\n\n       anger       0.88      0.91      0.89      1239\n        fear       0.83      0.89      0.86      1232\n       happy       0.86      0.82      0.84      1280\n        love       0.92      0.93      0.92      1194\n     sadness       0.88      0.80      0.84      1202\n    surprise       0.91      0.92      0.92      1175\n\n    accuracy                           0.88      7322\n   macro avg       0.88      0.88      0.88      7322\nweighted avg       0.88      0.88      0.88      7322\n\nAccuracy: 0.8787\nF1 Score: 0.8782\nPrecision: 0.8789\nSensitivity (Recall): 0.8787\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nsaved_model_dir = './saved_model'\nmodel.save_pretrained(saved_model_dir)\ntokenizer.save_pretrained(saved_model_dir)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:37:12.779134Z","iopub.execute_input":"2024-05-27T14:37:12.779520Z","iopub.status.idle":"2024-05-27T14:37:13.881768Z","shell.execute_reply.started":"2024-05-27T14:37:12.779481Z","shell.execute_reply":"2024-05-27T14:37:13.880877Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"('./saved_model/tokenizer_config.json',\n './saved_model/special_tokens_map.json',\n './saved_model/vocab.txt',\n './saved_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\nmodel_tflite_path = \"/kaggle/working/model.tflite\"\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\nwith open(model_tflite_path, \"wb\") as f:\n    f.write(tflite_model)\n\nfrom IPython.display import FileLink\nFileLink(model_tflite_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T14:52:40.267847Z","iopub.execute_input":"2024-05-27T14:52:40.268713Z","iopub.status.idle":"2024-05-27T14:54:29.581639Z","shell.execute_reply.started":"2024-05-27T14:52:40.268678Z","shell.execute_reply":"2024-05-27T14:54:29.580592Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Summary on the non-converted ops:\n---------------------------------\n * Accepted dialects: tfl, builtin, func\n * Non-Converted Ops: 222, Total Ops 1337, % non-converted = 16.60 %\n * 222 ARITH ops\n\n- arith.constant:  222 occurrences  (f32: 206, i32: 16)\n\n\n\n  (f32: 172)\n  (f32: 24)\n  (f32: 1)\n  (i32: 48)\n  (i32: 1)\n  (f32: 74)\n  (f32: 3, i32: 96)\n  (f32: 12)\n  (f32: 50)\n  (f32: 88)\n\n  (i32: 73)\n  (i32: 1)\n  (i32: 96)\n  (f32: 168, i32: 1)\n  (f32: 25)\n  (i32: 50)\n  (f32: 12)\n  (f32: 25)\n  (f32: 1, i32: 15)\n  (f32: 26)\n  (f32: 1)\n  (f32: 48)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model.tflite","text/html":"<a href='/kaggle/working/model.tflite' target='_blank'>/kaggle/working/model.tflite</a><br>"},"metadata":{}}]}]}